services:
  - type: web
    name: operator-api
    env: docker
    autoDeploy: true
    dockerfilePath: ./Dockerfile
    plan: standard
    healthCheckPath: /healthz
    disk:
      name: model-cache
      mountPath: /data
      sizeGB: 90
    envVars:
      # --- Model / Hugging Face ---
      - key: MODEL_ID
        value: xenon111/neur-0.0-full
      - key: MODEL_BASE_ID
        value: openai/gpt-oss-20b
      - key: HF_HOME
        value: /data/.cache/huggingface
      - key: HF_HUB_ENABLE_HF_TRANSFER
        value: "1"
      - key: TRANSFORMERS_NO_REMOTE_CODE
        value: "0"
      # If your repo is private, uncomment:
      # - key: HF_TOKEN
      #   sync: false

      # --- Browser & Headless ---
      - key: HEADLESS
        value: "1"
      - key: BROWSER_CHANNEL
        value: chrome

      # --- Model Behavior Flags ---
      - key: GEN_MAX_NEW_TOKENS
        value: "512"
      - key: GENERATION_TEMPERATURE
        value: "0.0"
      - key: MAX_AGENT_TURNS
        value: "6"
      - key: GEN_MAX_CONCURRENCY
        value: "2"
